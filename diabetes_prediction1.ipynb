{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimanshuGit-Hub/-Placement-Preparation-Module/blob/main/diabetes_prediction1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQMzSKbHgiI8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A4Y1V-ofnV7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import r2_score,confusion_matrix\n",
        "import warnings\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAhu5RUifnV9"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/diabetes_prediction_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkf-qC5xfnV-"
      },
      "outputs": [],
      "source": [
        "data.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdoRKCOqfnV_"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuH08tDhfnWA"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riCWjsZFfnWA"
      },
      "outputs": [],
      "source": [
        "def bar_plot(variable):\n",
        "\n",
        "    var = data[variable]\n",
        "\n",
        "    var_value = var.value_counts()\n",
        "\n",
        "    plt.figure(figsize=(6,3))\n",
        "    plt.bar(var_value.index, var_value,width= 1/(var.unique().size))\n",
        "    plt.xticks(var_value.index, var_value.index.values)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(variable)\n",
        "    plt.show()\n",
        "    print(\"{}: \\n {}\".format(variable,var_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SAMfOm6fnWA"
      },
      "outputs": [],
      "source": [
        "category1 = [\"hypertension\",\"heart_disease\",\"smoking_history\"]\n",
        "for c in category1:\n",
        "    bar_plot(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiTounEDfnWB"
      },
      "outputs": [],
      "source": [
        "data['bmi'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sexRUYCJfnWB"
      },
      "outputs": [],
      "source": [
        "pd.unique(data.smoking_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS7XHR5pfnWC"
      },
      "outputs": [],
      "source": [
        "pd.unique(data.gender)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmlYYZbIfnWC"
      },
      "source": [
        "For changing objects to integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXiLPUrxfnWD"
      },
      "outputs": [],
      "source": [
        "def change_string_to_int(column):\n",
        "    variables=pd.unique(data[column])\n",
        "    for item in range(variables.size):\n",
        "        data[column]=[item if each==variables[item] else each for each in data[column]]\n",
        "    return data[column]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wri0s_3lfnWE"
      },
      "outputs": [],
      "source": [
        "data[\"gender\"]=change_string_to_int(\"gender\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8wMZKstfnWE"
      },
      "outputs": [],
      "source": [
        "data[\"smoking_history\"]=change_string_to_int(\"smoking_history\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQkhBpzufnWE"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category1 = [\"hypertension\",\"heart_disease\",\"smoking_history\"]\n",
        "for c in category1:\n",
        "    bar_plot(c)"
      ],
      "metadata": {
        "id": "2VfBcFQ9C-Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZIgHcNwfnWF"
      },
      "outputs": [],
      "source": [
        "data['smoking_history'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfAMGLLrfnWF"
      },
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(data.corr(numeric_only=True), annot=True, linewidths=.5, fmt= '.1f',ax=ax,)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-hUl47RfnWF"
      },
      "outputs": [],
      "source": [
        "data.drop(\"gender\",axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQx8eXe2fnWG"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2smPH9o3fnWG"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3qDFbNFfnWG"
      },
      "source": [
        "Normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BTnt_JxfnWG"
      },
      "outputs": [],
      "source": [
        "data = (data - data.min())/(data.max()-data.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JHvi4hDfnWH"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "947iO_fKfnWH"
      },
      "outputs": [],
      "source": [
        "data[\"hypertension\"]= data[\"hypertension\"].astype(\"int64\")\n",
        "data[\"heart_disease\"]= data[\"heart_disease\"].astype(\"int64\")\n",
        "data[\"diabetes\"]= data[\"diabetes\"].astype(\"int64\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z06rUD-PfnWH"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXj3ZetzfnWH"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd6HKAqifnWI"
      },
      "source": [
        "<a id=\"6\"></a>\n",
        "# Split and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWATYyOgfnWI"
      },
      "outputs": [],
      "source": [
        "x = data.drop(\"diabetes\",axis=1)\n",
        "y = data.diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuuI9SUmPsZO"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title libs\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "# Import necessary libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import permutations, combinations\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Yqvq0JLB-zxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAlVrJBEPIkW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title false\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluate accuracy\n",
        "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Evaluate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# ROC curve and AUC\n",
        "# Assuming you have probabilities for positive class from your ensemble model\n",
        "y_probs = ensemble_classifier.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "# ROC Curve\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Metrics\n",
        "plt.subplot(2, 2, 3)\n",
        "metrics = {\n",
        "    'Accuracy': ensemble_accuracy,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1-Score': f1,\n",
        "}\n",
        "plt.bar(metrics.keys(), metrics.values())\n",
        "plt.title('Performance Metrics')\n",
        "plt.ylim(0, 1.2)\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gRp6Bp-I-mt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title false1\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Load your dataset (replace this with your own dataset)\n",
        "# X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Perform feature engineering\n",
        "# Example: Create polynomial features and scale the data\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(x)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_poly)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Initialize individual classifiers with default parameters\n",
        "gradient_boosting = GradientBoostingClassifier()\n",
        "lightgbm = LGBMClassifier()\n",
        "adaboost = AdaBoostClassifier()\n",
        "\n",
        "# Define parameter grids for each base classifier\n",
        "param_grid_gb = {'n_estimators': [50, 100, 200],\n",
        "                 'learning_rate': [0.01, 0.1, 0.2]}\n",
        "param_grid_lgbm = {'n_estimators': [50, 100, 200],\n",
        "                   'learning_rate': [0.01, 0.1, 0.2]}\n",
        "param_grid_adaboost = {'n_estimators': [50, 100, 200],\n",
        "                       'learning_rate': [0.01, 0.1, 0.2]}\n",
        "\n",
        "# Perform Grid Search for each base classifier\n",
        "grid_search_gb = GridSearchCV(gradient_boosting, param_grid_gb, cv=3)\n",
        "grid_search_lgbm = GridSearchCV(lightgbm, param_grid_lgbm, cv=3)\n",
        "grid_search_adaboost = GridSearchCV(adaboost, param_grid_adaboost, cv=3)\n",
        "\n",
        "# Fit the models with the best parameters\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "grid_search_lgbm.fit(X_train, y_train)\n",
        "grid_search_adaboost.fit(X_train, y_train)\n",
        "\n",
        "# Get the best models\n",
        "best_gb = grid_search_gb.best_estimator_\n",
        "best_lgbm = grid_search_lgbm.best_estimator_\n",
        "best_adaboost = grid_search_adaboost.best_estimator_\n",
        "\n",
        "# Create a list of base models\n",
        "base_models = [('Gradient Boosting', best_gb),\n",
        "               ('LightGBM', best_lgbm),\n",
        "               ('AdaBoost', best_adaboost)]\n",
        "\n",
        "# Create a stacking classifier with a meta-model\n",
        "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
        "\n",
        "# Train the stacking classifier on the training data\n",
        "stacking_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the stacking classifier on the test data\n",
        "y_pred = stacking_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the ensemble\n",
        "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Ensemble Accuracy with Stacking after Hyperparameter Tuning: {ensemble_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOhtNvVdvo0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VACvk9-hKLpi"
      },
      "outputs": [],
      "source": [
        "# @title MAIN MODEL CODE\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "# Load your dataset (replace this with your own dataset)\n",
        "\n",
        "\n",
        "# Perform feature engineering\n",
        "# Example: Select top k features using ANOVA F-statistic\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets with selected and scaled features\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize individual classifiers\n",
        "gradient_boosting = GradientBoostingClassifier()\n",
        "lightgbm = LGBMClassifier()\n",
        "adaboost = AdaBoostClassifier()\n",
        "\n",
        "# Create an ensemble of classifiers using majority voting\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[('Gradient Boosting', gradient_boosting),\n",
        "                ('LightGBM', lightgbm),\n",
        "                ('AdaBoost', adaboost)],\n",
        "    voting='hard'  # Use majority voting\n",
        ")\n",
        "\n",
        "# Hyperparameter tuning for each base classifier\n",
        "param_grid_gb = {'n_estimators': [50, 100, 200],\n",
        "                 'learning_rate': [0.01, 0.1, 0.2]}\n",
        "param_grid_lgbm = {'n_estimators': [50, 100, 200],\n",
        "                   'learning_rate': [0.01, 0.1, 0.2]}\n",
        "param_grid_adaboost = {'n_estimators': [50, 100, 200],\n",
        "                       'learning_rate': [0.01, 0.1, 0.2]}\n",
        "\n",
        "grid_search_gb = GridSearchCV(gradient_boosting, param_grid_gb, cv=3)\n",
        "grid_search_lgbm = GridSearchCV(lightgbm, param_grid_lgbm, cv=3)\n",
        "grid_search_adaboost = GridSearchCV(adaboost, param_grid_adaboost, cv=3)\n",
        "\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "grid_search_lgbm.fit(X_train, y_train)\n",
        "grid_search_adaboost.fit(X_train, y_train)\n",
        "\n",
        "best_gb = grid_search_gb.best_estimator_\n",
        "best_lgbm = grid_search_lgbm.best_estimator_\n",
        "best_adaboost = grid_search_adaboost.best_estimator_\n",
        "\n",
        "# Create an ensemble classifier with the best models\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[('Gradient Boosting', best_gb),\n",
        "                ('LightGBM', best_lgbm),\n",
        "                ('AdaBoost', best_adaboost)],\n",
        "    voting='hard'  # Use majority voting\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the ensemble classifier on the test data\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the ensemble\n",
        "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Ensemble Accuracy after Hyperparameter Tuning: {ensemble_accuracy:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('model.pkl')"
      ],
      "metadata": {
        "id": "jzuwpf0X2mBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "id": "lP2Cv74H8qAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D78NA2gT88kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model as a .pkl file\n",
        "with open('model1.pkl', 'wb') as file:\n",
        "    pickle.dump(ensemble_classifier, file)"
      ],
      "metadata": {
        "id": "meE8IsLp2nEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['blood_glucose_level'].max()"
      ],
      "metadata": {
        "id": "HRhkTXp8HkB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TuiWZdqsIji-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "id": "0lCvCFqGIjOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "P98wL9V9I9QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501\n",
        "\n"
      ],
      "metadata": {
        "id": "imvNiCk3I3Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ro_fz9LBIiO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the trained model and scaler\n",
        "model = joblib.load('model.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# Title of the app\n",
        "st.title('Health Risk Prediction App')\n",
        "\n",
        "# Subtitle or description\n",
        "st.write('This app predicts health risks based on user inputs.')\n",
        "\n",
        "# Function to get user input\n",
        "def get_user_input():\n",
        "    age = st.sidebar.number_input('Age', min_value=0, max_value=120, value=25)\n",
        "    hypertension = st.sidebar.selectbox('Hypertension', options=[0, 1], index=0)\n",
        "    heart_disease = st.sidebar.selectbox('Heart Disease', options=[0, 1], index=0)\n",
        "    smoking_history = st.sidebar.selectbox('Smoking History', options=['no info','never', 'former', 'current','not current','ever'], index=0, format_func=lambda x: 1 if x == 'no info' else if 0 if x == 'never' else if 3 if x == 'former' else if 2 if x == 'current' else if 5 if x == 'not current' else if 4 if x == 'ever')\n",
        "    bmi = st.sidebar.number_input('BMI', min_value=10.0, max_value=100, value=20.0)\n",
        "    HbA1c_level = st.sidebar.number_input('HbA1c Level', min_value=2.0, max_value=15.0, value=5.0)\n",
        "    blood_glucose_level = st.sidebar.number_input('Blood Glucose Level', min_value=50, max_value=400, value=100)\n",
        "\n",
        "    data = {\n",
        "        'age': age,\n",
        "        'hypertension': hypertension,\n",
        "        'heart_disease': heart_disease,\n",
        "        'smoking_history': smoking_history,\n",
        "        'bmi': bmi,\n",
        "        'HbA1c_level': HbA1c_level,\n",
        "        'blood_glucose_level': blood_glucose_level\n",
        "    }\n",
        "\n",
        "    features = pd.DataFrame(data, index=[0])\n",
        "    return features\n",
        "\n",
        "# Get user input\n",
        "user_input = get_user_input()\n",
        "\n",
        "# Display user input\n",
        "st.write('User Input:')\n",
        "st.write(user_input)\n",
        "\n",
        "# Convert categorical data if necessary\n",
        "user_input['smoking_history'] = user_input['smoking_history'].map({'never': 0, 'former': 1, 'current': 2})\n",
        "\n",
        "# Normalize the user input using the same scaler\n",
        "user_input_scaled = scaler.transform(user_input)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(user_input_scaled)\n",
        "\n",
        "# Display prediction\n",
        "st.write('Prediction:')\n",
        "st.write(prediction)\n"
      ],
      "metadata": {
        "id": "AE2gSfQ6JMDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, cross_val_score\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Function to plot learning curve\n",
        "def plot_learning_curve(estimator, title, x, y, cv=3, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, x, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "# Plot learning curve for ensemble classifier\n",
        "title = \"Learning Curves (Ensemble Classifier)\"\n",
        "plot_learning_curve(ensemble_classifier, title, x, y, cv=3, n_jobs=-1)\n",
        "plt.show()\n",
        "\n",
        "# Function to plot accuracy vs. number of estimators\n",
        "def plot_accuracy_vs_estimators(estimator, param_name, param_range, x, y, cv=3):\n",
        "    train_scores, test_scores = [], []\n",
        "    for param in param_range:\n",
        "        estimator.set_params(**{param_name: param})\n",
        "        train_score = cross_val_score(estimator, x, y, cv=cv, scoring='accuracy')\n",
        "        test_score = cross_val_score(estimator, x, y, cv=cv, scoring='accuracy')\n",
        "        train_scores.append(train_score.mean())\n",
        "        test_scores.append(test_score.mean())\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(param_range, train_scores, label='Training accuracy')\n",
        "    plt.plot(param_range, test_scores, label='Validation accuracy')\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'Accuracy vs. {param_name} for {estimator.__class__.__name__}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Plot for Gradient Boosting Classifier\n",
        "plot_accuracy_vs_estimators(GradientBoostingClassifier(), 'n_estimators', [50, 100, 200], X_train, y_train)\n",
        "\n",
        "# Plot for LGBM Classifier\n",
        "plot_accuracy_vs_estimators(LGBMClassifier(), 'n_estimators', [50, 100, 200], X_train, y_train)\n",
        "\n",
        "# Plot for AdaBoost Classifier\n",
        "plot_accuracy_vs_estimators(AdaBoostClassifier(), 'n_estimators', [50, 100, 200], X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Hu4EZxdzGTw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Function to plot accuracy vs. number of estimators\n",
        "def plot_accuracy_vs_estimators(estimator, param_name, param_range, x, y, cv=3):\n",
        "    train_scores, test_scores = [], []\n",
        "    for param in param_range:\n",
        "        estimator.set_params(**{param_name: param})\n",
        "        train_score = cross_val_score(estimator, x, y, cv=cv, scoring='accuracy')\n",
        "        test_score = cross_val_score(estimator, x, y, cv=cv, scoring='accuracy')\n",
        "        train_scores.append(train_score.mean())\n",
        "        test_scores.append(test_score.mean())\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(param_range, train_scores, label='Training accuracy', color='blue', linestyle='-', marker='o')\n",
        "    plt.plot(param_range, test_scores, label='Validation accuracy', color='orange', linestyle='--', marker='x')\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'Accuracy vs. {param_name} for {estimator.__class__.__name__}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Plot for Gradient Boosting Classifier\n",
        "plot_accuracy_vs_estimators(GradientBoostingClassifier(), 'n_estimators', [50, 100, 200], X_train, y_train)\n",
        "\n",
        "# Plot for LGBM Classifier\n",
        "plot_accuracy_vs_estimators(LGBMClassifier(), 'n_estimators', [50, 100, 200], X_train, y_train)\n",
        "\n",
        "# Plot for AdaBoost Classifier\n",
        "plot_accuracy_vs_estimators(AdaBoostClassifier(), 'n_estimators', [50, 100, 200], X_train, y_train)\n"
      ],
      "metadata": {
        "id": "3SCkasNHVJjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importance(estimator, X_train, title):\n",
        "    feature_importances = estimator.feature_importances_\n",
        "    sorted_idx = np.argsort(feature_importances)\n",
        "    pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(pos, feature_importances[sorted_idx], align='center')\n",
        "    plt.yticks(pos, np.array(data.feature_names)[sorted_idx])\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Plot feature importance for Gradient Boosting Classifier\n",
        "plot_feature_importance(best_gb, X_train, 'Feature Importance (Gradient Boosting)')\n",
        "\n",
        "# Plot feature importance for LightGBM Classifier\n",
        "plot_feature_importance(best_lgbm, X_train, 'Feature Importance (LightGBM)')\n",
        "\n",
        "# Plot feature importance for AdaBoost Classifier\n",
        "plot_feature_importance(best_adaboost, X_train, 'Feature Importance (AdaBoost)')"
      ],
      "metadata": {
        "id": "5gGvKVPxXeVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, cross_val_score\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize individual classifiers\n",
        "gradient_boosting = GradientBoostingClassifier()\n",
        "lightgbm = LGBMClassifier()\n",
        "adaboost = AdaBoostClassifier()\n",
        "\n",
        "# Hyperparameter tuning for each base classifier\n",
        "param_grid_gb = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n",
        "param_grid_lgbm = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n",
        "param_grid_adaboost = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n",
        "\n",
        "grid_search_gb = GridSearchCV(gradient_boosting, param_grid_gb, cv=3)\n",
        "grid_search_lgbm = GridSearchCV(lightgbm, param_grid_lgbm, cv=3)\n",
        "grid_search_adaboost = GridSearchCV(adaboost, param_grid_adaboost, cv=3)\n",
        "\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "grid_search_lgbm.fit(X_train, y_train)\n",
        "grid_search_adaboost.fit(X_train, y_train)\n",
        "\n",
        "best_gb = grid_search_gb.best_estimator_\n",
        "best_lgbm = grid_search_lgbm.best_estimator_\n",
        "best_adaboost = grid_search_adaboost.best_estimator_\n",
        "\n",
        "# Create an ensemble classifier with the best models using hard voting\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[('Gradient Boosting', best_gb), ('LightGBM', best_lgbm), ('AdaBoost', best_adaboost)],\n",
        "    voting='hard'  # Use hard voting\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the ensemble classifier on the test data\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the ensemble\n",
        "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Ensemble Accuracy after Hyperparameter Tuning: {ensemble_accuracy:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Function to plot learning curve\n",
        "def plot_learning_curve(estimator, title, X, y, cv=3, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "# Plot learning curve for ensemble classifier\n",
        "title = \"Learning Curves (Ensemble Classifier)\"\n",
        "plot_learning_curve(ensemble_classifier, title, X, y, cv=3, n_jobs=-1)\n",
        "plt.show()\n",
        "\n",
        "# Function to plot accuracy vs. number of estimators\n",
        "def plot_accuracy_vs_estimators(estimator, param_name, param_range, X, y, cv=3):\n",
        "    train_scores, test_scores = [], []\n",
        "    for param in param_range:\n",
        "        estimator.set_params(**{param_name: param})\n",
        "        train_score = cross_val_score(estimator, X, y, cv=cv, scoring='accuracy')\n",
        "        test_score = cross_val_score(estimator, X, y, cv=cv, scoring='accuracy')\n",
        "        train_scores.append(train_score.mean())\n",
        "        test_scores.append(test_score.mean())\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(param_range, train_scores, label='Training accuracy')\n",
        "    plt.plot(param_range, test_scores, label='Validation accuracy')\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'Accuracy vs. {param_name} for {estimator.__class__.__name__}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Plot for Gradient Boosting Classifier\n",
        "plot_accuracy_vs_estimators(GradientBoostingClassifier(), 'n_estimators', [50, 100, 200], X_train, y_train)\n",
        "\n",
        "# Plot for LGBM Classifier\n",
        "plot_accuracy_vs_estimators(LGBMClassifier(), 'n_estimators', [50, 100, 200], X_train, y_train)\n",
        "\n",
        "# Plot for AdaBoost Classifier\n",
        "plot_accuracy_vs_estimators(AdaBoostClassifier(), 'n_estimators', [50, 100, 200], X_train, y_train)\n"
      ],
      "metadata": {
        "id": "FsY7m9c6GUwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6BzFYVdGVFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##real\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "individual_models = {\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"LightGBM\": LGBMClassifier()\n",
        "}\n",
        "\n",
        "model_metrics = []\n",
        "\n",
        "for model_name, model in individual_models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    model_metrics.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall\n",
        "    })\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "results_df = pd.DataFrame(model_metrics)\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "fs9dPv4kvAOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions using the ensemble classifier on the test data\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Evaluate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "# Metrics\n",
        "plt.subplot(2, 2, 3)\n",
        "metrics = {\n",
        "    'Accuracy': ensemble_accuracy,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1-Score': f1,\n",
        "}\n",
        "plt.bar(metrics.keys(), metrics.values())\n",
        "plt.title('Performance Metrics')\n",
        "plt.ylim(0, 1.2)\n",
        "\n",
        "# Display the classification report\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.text(0.1, 0.5, class_report, fontsize=10)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fTBycrjCyWos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Calculate the precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
        "\n",
        "# Plot the precision-recall curve\n",
        "plt.plot(precision, recall, label='Ensemble Classifier')\n",
        "plt.xlabel('Precision')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Precision-Recall Curve for Diabetes Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i1CZ2uUQZA8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Calculate the feature importance\n",
        "importances = ensemble_classifier.estimators_[0].feature_importances_\n",
        "\n",
        "# Sort the features by importance\n",
        "features = x.columns\n",
        "indices = np.argsort(importances)[::-1]"
      ],
      "metadata": {
        "id": "VyQFWkLNZF8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.inspection import partial_dependence\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate the partial dependence values.\n",
        "pdp_values = partial_dependence(model, features, X)\n",
        "\n",
        "    # Plot the partial dependence plot.\n",
        "plt.plot(pdp_values[0], pdp_values[1])\n",
        "\n",
        "    # Set the axis labels.\n",
        "plt.xlabel(feature_names[features[0]])\n",
        "plt.ylabel('Predicted Probability')\n",
        "\n",
        "    # Set the title of the plot.\n",
        "plt.title('Partial Dependence Plot for Feature {}'.format(feature_names[features[0]]))\n",
        "\n",
        "    # Show the plot.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UQh3ts9-ZsmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the predictions from each base classifier in the ensemble\n",
        "predictions = [classifier.predict(x) for classifier in ensemble_classifier.estimators_]\n",
        "\n",
        "# Plot the individual predictions\n",
        "fig, axes = plt.subplots(len(ensemble_classifier.estimators_))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.scatter(np.arange(len(x)), predictions[i])\n",
        "    ax.set_xlabel('Case')\n",
        "    ax.set_ylabel('Predicted Probability of Diabetes')\n",
        "    ax.set_title(f'Classifier {i + 1}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3zcTMwwaZwFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import calibration_curve\n",
        "\n",
        "# Calculate the calibration curve\n",
        "probabilities = ensemble_classifier.predict_proba(x)[:, 1]\n",
        "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, probabilities)\n",
        "\n",
        "# Plot the calibration curve\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Ideal')\n",
        "plt.plot(mean_predicted_value, fraction_of_positives, 'o-', label='Ensemble Classifier')\n",
        "plt.xlabel('Mean Predicted Value')\n",
        "plt.ylabel('Fraction of Positives')\n",
        "plt.title('Calibration Curve for Diabetes Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ABTyMRlsZ0Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRSgOeq5RC5s"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Make predictions using the ensemble classifier on the test data\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Calculate confusion matrix\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWj94-LSREAb"
      },
      "outputs": [],
      "source": [
        "# Perform feature engineering and selection as needed\n",
        "\n",
        "# Resample the dataset to balance classes\n",
        "# Example for oversampling the minority class using SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Hyperparameter tuning with the resampled data\n",
        "# ...\n",
        "\n",
        "# Create an ensemble classifier with the best models\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[('Gradient Boosting', best_gb),\n",
        "                ('LightGBM', best_lgbm),\n",
        "                ('AdaBoost', best_adaboost)],\n",
        "    voting='hard'  # Use majority voting\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the resampled training data\n",
        "ensemble_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions using the ensemble classifier on the test data\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the ensemble\n",
        "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Ensemble Accuracy after Improvements: {ensemble_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate other performance metrics as mentioned above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QmF31Ncjfj5"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uH9rZDBhNzj"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "# Load your dataset (replace this with your own dataset)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifiers for different techniques\n",
        "classifiers = {\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(),\n",
        "    \"Deep Learning (MLP)\": MLPClassifier(),\n",
        "    \"LightGBM\": LGBMClassifier(),\n",
        "    \"XGBoost\": XGBClassifier(),\n",
        "    \"CatBoost\": CatBoostClassifier(iterations=500, verbose=0),\n",
        "    \"k-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Naive Bayes (Gaussian)\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
        "    \"Stochastic Gradient Descent\": SGDClassifier(),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(),\n",
        "    \"Naive Bayes (Multinomial)\": MultinomialNB(),\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "results = {}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[name] = accuracy\n",
        "\n",
        "# Display the accuracy of each technique\n",
        "for name, accuracy in results.items():\n",
        "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lv4N6RjSlFHp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from collections import Counter\n",
        "\n",
        "# Load your dataset (replace this with your own dataset)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifiers for different techniques\n",
        "classifiers = {\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(probability=True),  # Note: Set probability=True for voting\n",
        "    \"Deep Learning (MLP)\": MLPClassifier(),\n",
        "    \"LightGBM\": LGBMClassifier(),\n",
        "    \"XGBoost\": XGBClassifier(),\n",
        "    \"CatBoost\": CatBoostClassifier(iterations=500, verbose=0),\n",
        "}\n",
        "\n",
        "# Train each classifier and make predictions on the test data\n",
        "predictions = {}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    predictions[name] = y_pred\n",
        "\n",
        "# Perform majority voting ensemble\n",
        "ensemble_predictions = np.zeros_like(y_pred)\n",
        "for name, y_pred in predictions.items():\n",
        "    ensemble_predictions += y_pred\n",
        "\n",
        "# Get the majority voted prediction\n",
        "ensemble_predictions = np.round(ensemble_predictions / len(classifiers))\n",
        "\n",
        "# Calculate accuracy for the ensemble\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VphNTB0zfnWI"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoEc7aS5fnWI"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(y_train).reshape(-1,1)\n",
        "y_test = np.array(y_test).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUrpqrOcfnWJ"
      },
      "outputs": [],
      "source": [
        "print(\"x train: \",x_train.shape)\n",
        "print(\"x test: \",x_test.shape)\n",
        "print(\"y train: \",y_train.shape)\n",
        "print(\"y test: \",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ8dDfZAfnWJ"
      },
      "outputs": [],
      "source": [
        "logreg = linear_model.LogisticRegression(random_state = 42,max_iter= 200,)\n",
        "print(\"test accuracy: {} \".format(logreg.fit(x_train, y_train).score(x_test, y_test)))\n",
        "print(\"train accuracy: {} \".format(logreg.fit(x_train, y_train).score(x_train, y_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vixCQEqRfnWJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "y_pred = logreg.fit(x_train, y_train).predict(x_test)\n",
        "cm = confusion_matrix(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv8I_RvofnWK"
      },
      "outputs": [],
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax);\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "ax.xaxis.set_ticklabels(['diabetes','not_diabetes']); ax.yaxis.set_ticklabels(['diabetes','not_diabetes']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI5MTmJPfnWK"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMdUjBUJfnWL"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n",
        "# Create a decision tree classifier\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5ZksB3CfnWL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHIN593efnWL"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euvneH9dfnWL"
      },
      "outputs": [],
      "source": [
        "# Create a random forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Train the model\n",
        "rf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyDY0cNrfnWT"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = rf.predict(x_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoyhQJgmfnWT",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"test accuracy: {} \".format(rf.fit(x_train, y_train).score(x_test, y_test)))\n",
        "print(\"train accuracy: {} \".format(rf.fit(x_train, y_train).score(x_train, y_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn5YfxwmfnWU",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "y_pred = rf.predict(x_test)\n",
        "cm = confusion_matrix(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz-lHWgSfnWU"
      },
      "outputs": [],
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax);\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "ax.xaxis.set_ticklabels(['diabetes','not_diabetes']); ax.yaxis.set_ticklabels(['diabetes','not_diabetes']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnX4n4K2fnWU"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "\n",
        "# Create a KNN classifier\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzgomBs5fnWV"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "\n",
        "# Create a Gaussian Naive Bayes classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJk2dARqfnWV"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "\n",
        "\n",
        "# Create an SVR regressor\n",
        "model = SVR()\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = np.mean((y_pred - y_test)**2)\n",
        "\n",
        "# Print the mean squared error\n",
        "print('Mean squared error:', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvyakO2CfnWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb-5rdJbfnWV"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REywUczkfnWW"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAs-ydpCfnWW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Create a random forest classifier\n",
        "clf1 = RandomForestClassifier()\n",
        "\n",
        "# Create a logistic regression classifier\n",
        "clf2 = LogisticRegression()\n",
        "\n",
        "# Create an ensemble classifier\n",
        "ensemble_clf = VotingClassifier(estimators=[('rf', clf1), ('lr', clf2)], voting='soft')\n",
        "\n",
        "# Train the ensemble classifier\n",
        "ensemble_clf.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_clf.predict_proba(x_test)\n",
        "\n",
        "# Take the weighted average of the probabilities\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4WfoWowfnWW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Create a random forest classifier\n",
        "clf1 = RandomForestClassifier()\n",
        "\n",
        "# Create a logistic regression classifier\n",
        "clf2 = LogisticRegression()\n",
        "\n",
        "# Create an ensemble classifier\n",
        "# Create an ensemble classifier\n",
        "ensemble_clf = VotingClassifier(estimators=[('rf', clf1), ('lr', clf2)], voting='hard')\n",
        "\n",
        "# Train the ensemble classifier\n",
        "ensemble_clf.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_clf.predict(x_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2IoC7safnWX"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (you should replace this with your own dataset)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest model\n",
        "random_forest.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions using the Random Forest model\n",
        "rf_predictions = random_forest.predict(x_test)\n",
        "\n",
        "# Calculate accuracy for Random Forest\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "\n",
        "# Create an AdaBoost classifier with Random Forest as the base estimator\n",
        "adaboost_rf = AdaBoostClassifier(base_estimator=random_forest, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the AdaBoost model\n",
        "adaboost_rf.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions using the AdaBoost model\n",
        "adaboost_rf_predictions = adaboost_rf.predict(x_test)\n",
        "\n",
        "# Calculate accuracy for AdaBoost with Random Forest\n",
        "adaboost_rf_accuracy = accuracy_score(y_test, adaboost_rf_predictions)\n",
        "print(f\"AdaBoost with Random Forest Accuracy: {adaboost_rf_accuracy}\")\n",
        "\n",
        "# Create a Gradient Boosting classifier\n",
        "gradient_boosting = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Gradient Boosting model\n",
        "gradient_boosting.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions using the Gradient Boosting model\n",
        "gb_predictions = gradient_boosting.predict(x_test)\n",
        "\n",
        "# Calculate accuracy for Gradient Boosting\n",
        "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
        "print(f\"Gradient Boosting Accuracy: {gb_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K04htvcMfnWX"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import permutations, combinations\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Number of Random Forest models in the ensemble\n",
        "num_models = 5\n",
        "\n",
        "# Create an empty list to store the individual Random Forest models\n",
        "random_forest_models = []\n",
        "\n",
        "# Train multiple Random Forest models\n",
        "for i in range(num_models):\n",
        "    # Create a Random Forest classifier\n",
        "    random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Generate random indices for sampling with replacement within the valid range\n",
        "    random_indices = np.random.randint(0, len(X_train), len(X_train))\n",
        "    X_sampled = X_train.iloc[random_indices]\n",
        "    y_sampled = y_train.iloc[random_indices]\n",
        "\n",
        "    # Train the Random Forest model on the sampled data\n",
        "    random_forest.fit(X_sampled, y_sampled)\n",
        "\n",
        "    # Append the trained model to the list\n",
        "    random_forest_models.append(random_forest)\n",
        "\n",
        "# Make predictions using each Random Forest model\n",
        "rf_predictions = [model.predict(X_test) for model in random_forest_models]\n",
        "\n",
        "# Aggregate the predictions by taking the majority vote (voting)\n",
        "bagged_predictions = np.round(np.mean(rf_predictions, axis=0)).astype(int)\n",
        "\n",
        "# Calculate accuracy for the bagged model\n",
        "bagged_accuracy = accuracy_score(y_test, bagged_predictions)\n",
        "print(f\"Bagged Random Forest Accuracy: {bagged_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWsxSkNJfnWY",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import permutations, combinations\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset (you should replace this with your own dataset)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Number of base models (Bagged Random Forest and Gradient Boosting)\n",
        "num_base_models = 2\n",
        "\n",
        "# Create empty lists to store the individual base models\n",
        "base_models = []\n",
        "\n",
        "# Train Bagged Random Forest and Gradient Boosting models\n",
        "for i in range(num_base_models):\n",
        "    if i == 0:\n",
        "        # Create and train Bagged Random Forest\n",
        "        base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    else:\n",
        "        # Create and train Gradient Boosting model\n",
        "        base_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Train the base model\n",
        "    base_model.fit(X_train, y_train)\n",
        "\n",
        "    # Append the trained model to the list\n",
        "    base_models.append(base_model)\n",
        "\n",
        "# Generate predictions from the base models\n",
        "base_predictions = []\n",
        "\n",
        "for model in base_models:\n",
        "    base_predictions.append(model.predict(X_test))\n",
        "\n",
        "# Combine the predictions from the base models\n",
        "combined_predictions = np.vstack(base_predictions).T  # Stack predictions horizontally\n",
        "\n",
        "# Create a meta-model (Logistic Regression)\n",
        "meta_model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the meta-model on the combined predictions\n",
        "meta_model.fit(combined_predictions, y_test)\n",
        "\n",
        "# Make predictions using the base models on the test data\n",
        "base_model_predictions_test = np.vstack([model.predict(X_test) for model in base_models]).T\n",
        "\n",
        "# Make predictions using the meta-model on the combined base model predictions\n",
        "final_predictions = meta_model.predict(base_model_predictions_test)\n",
        "\n",
        "# Calculate accuracy for the ensemble\n",
        "ensemble_accuracy = accuracy_score(y_test, final_predictions)\n",
        "\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy}\")\n",
        "print(classification_report(y_test, final_predictions))\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Perform cross-validation to assess overfitting\n",
        "cross_val_scores = cross_val_score(meta_model, combined_predictions, y_test, cv=5)  # 5-fold cross-validation\n",
        "\n",
        "# Calculate accuracy for the ensemble on the test data\n",
        "ensemble_accuracy = accuracy_score(y_test, meta_model.predict(combined_predictions))\n",
        "\n",
        "print(f\"Ensemble Accuracy on Test Data: {ensemble_accuracy}\")\n",
        "print(f\"Cross-Validation Scores: {cross_val_scores}\")\n",
        "print(f\"Mean Cross-Validation Score: {np.mean(cross_val_scores)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK-Y9rgDfnWY"
      },
      "outputs": [],
      "source": [
        "!pip install --user imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7czAJ1NkfnWZ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zQsUKbxfnWZ",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import permutations, combinations\n",
        "\n",
        "\n",
        "\n",
        "# Number of base models (Bagged Random Forest and Gradient Boosting)\n",
        "num_base_models = 2\n",
        "\n",
        "# Create empty lists to store the individual base models\n",
        "base_models1 = []\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "# Train Bagged Random Forest and Gradient Boosting models\n",
        "for i in range(num_base_models):\n",
        "    if i == 0:\n",
        "        # Create and train Bagged Random Forest\n",
        "        base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    else:\n",
        "        # Create and train Gradient Boosting model\n",
        "        base_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Train the base model\n",
        "    base_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # Append the trained model to the list\n",
        "    base_models.append(base_model)\n",
        "\n",
        "# Generate predictions from the base models\n",
        "base_predictions = []\n",
        "\n",
        "for model in base_models:\n",
        "    base_predictions.append(model.predict(X_test))\n",
        "\n",
        "# Combine the predictions from the base models\n",
        "combined_predictions = np.vstack(base_predictions).T  # Stack predictions horizontally\n",
        "\n",
        "# Create a meta-model (Logistic Regression)\n",
        "meta_model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the meta-model on the combined predictions\n",
        "meta_model.fit(combined_predictions, y_test)\n",
        "\n",
        "# Make predictions using the base models on the test data\n",
        "base_model_predictions_test = np.vstack([model.predict(X_test) for model in base_models]).T\n",
        "\n",
        "# Make predictions using the meta-model on the combined base model predictions\n",
        "final_predictions = meta_model.predict(base_model_predictions_test)\n",
        "\n",
        "# Calculate accuracy for the ensemble\n",
        "ensemble_accuracy = accuracy_score(y_test, final_predictions)\n",
        "\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy}\")\n",
        "print(classification_report(y_test, final_predictions))\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Perform cross-validation to assess overfitting\n",
        "cross_val_scores = cross_val_score(meta_model, combined_predictions, y_test, cv=5)  # 5-fold cross-validation\n",
        "\n",
        "# Calculate accuracy for the ensemble on the test data\n",
        "ensemble_accuracy = accuracy_score(y_test, meta_model.predict(combined_predictions))\n",
        "\n",
        "print(f\"Ensemble Accuracy on Test Data: {ensemble_accuracy}\")\n",
        "print(f\"Cross-Validation Scores: {cross_val_scores}\")\n",
        "print(f\"Mean Cross-Validation Score: {np.mean(cross_val_scores)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8s6QutmfnWa"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import permutations, combinations\n",
        "\n",
        "\n",
        "# Load your dataset (replace this with your own dataset)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize individual classifiers\n",
        "gradient_boosting = GradientBoostingClassifier()\n",
        "lightgbm = LGBMClassifier()\n",
        "adaboost = AdaBoostClassifier()\n",
        "\n",
        "# Create an ensemble of classifiers using majority voting\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[('Gradient Boosting', gradient_boosting),\n",
        "                ('LightGBM', lightgbm),\n",
        "                ('AdaBoost', adaboost)],\n",
        "    voting='hard'  # Use majority voting\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the ensemble classifier on the test data\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the ensemble\n",
        "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3id6TSVylZD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import permutations, combinations\n",
        "\n",
        "# Load the dataset (replace with your dataset loading code)\n",
        "\n",
        "X = X_train\n",
        "y = y_train\n",
        "X_train.head()\n",
        "\n",
        "# Define the base learners\n",
        "base_learners = {\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Define the meta-learner\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# List to store results\n",
        "results = []\n",
        "\n",
        "# Generate all possible combinations of base learners\n",
        "for i in range(1, len(base_learners) + 1):\n",
        "    combinations_list = list(combinations(base_learners.keys(), i))\n",
        "    for combo in combinations_list:\n",
        "        # Create an ensemble model with the selected base learners\n",
        "        ensemble_learners = [base_learners[learner] for learner in combo]\n",
        "\n",
        "        # Train the ensemble model using cross-validation\n",
        "        combined_predictions = np.vstack([model.fit(X, y).predict(X) for model in ensemble_learners]).T\n",
        "        cross_val_scores = cross_val_score(meta_learner, combined_predictions, y, cv=5)\n",
        "\n",
        "        # Calculate the mean accuracy and store the results\n",
        "        mean_accuracy = np.mean(cross_val_scores)\n",
        "        results.append({\n",
        "            'Base Learners': combo,\n",
        "            'Meta Learner': 'Logistic Regression',\n",
        "            'Mean Accuracy': mean_accuracy\n",
        "        })\n",
        "\n",
        "# Sort results by mean accuracy in descending order\n",
        "results.sort(key=lambda x: x['Mean Accuracy'], reverse=True)\n",
        "\n",
        "# Print results\n",
        "for idx, result in enumerate(results):\n",
        "    print(f\"Ensemble {idx + 1} - Base Learners: {result['Base Learners']}, Mean Accuracy: {result['Mean Accuracy']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrqiHtlg9gm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0iBkjxBz4C2"
      },
      "outputs": [],
      "source": [
        "# @title 0.9723\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "# Import necessary libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from itertools import permutations, combinations\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Define parameter grids for each base classifier\n",
        "param_grid_gb = {'n_estimators': [50, 100, 200],\n",
        "                 'learning_rate': [0.01, 0.1, 0.2]}\n",
        "param_grid_lgbm = {'n_estimators': [50, 100, 200],\n",
        "                   'learning_rate': [0.01, 0.1, 0.2]}\n",
        "param_grid_adaboost = {'n_estimators': [50, 100, 200],\n",
        "                       'learning_rate': [0.01, 0.1, 0.2]}\n",
        "\n",
        "# Perform Grid Search for each base classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Define your classifiers\n",
        "gradient_boosting = GradientBoostingClassifier()\n",
        "lightgbm = LGBMClassifier()\n",
        "adaboost = AdaBoostClassifier()\n",
        "grid_search_gb = GridSearchCV(gradient_boosting, param_grid_gb, cv=3)\n",
        "grid_search_lgbm = GridSearchCV(lightgbm, param_grid_lgbm, cv=3)\n",
        "grid_search_adaboost = GridSearchCV(adaboost, param_grid_adaboost, cv=3)\n",
        "\n",
        "# Fit the models with the best parameters\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "grid_search_lgbm.fit(X_train, y_train)\n",
        "grid_search_adaboost.fit(X_train, y_train)\n",
        "\n",
        "# Get the best models\n",
        "best_gb = grid_search_gb.best_estimator_\n",
        "best_lgbm = grid_search_lgbm.best_estimator_\n",
        "best_adaboost = grid_search_adaboost.best_estimator_\n",
        "\n",
        "# Create an ensemble classifier with the best models\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[('Gradient Boosting', best_gb),\n",
        "                ('LightGBM', best_lgbm),\n",
        "                ('AdaBoost', best_adaboost)],\n",
        "    voting='soft'  # Use majority voting\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the ensemble classifier on the test data\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy for the ensemble\n",
        "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Ensemble Accuracy after Hyperparameter Tuning: {ensemble_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz"
      ],
      "metadata": {
        "id": "Gd_pWkvbvr8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Create Digraph object\n",
        "dot = Digraph()\n",
        "\n",
        "# Define nodes\n",
        "dot.node('A', 'Start')\n",
        "dot.node('B', 'Define change_string_to_int')\n",
        "dot.node('C', 'Extract unique values for the specified column')\n",
        "dot.node('D', 'Iterate over unique values')\n",
        "dot.node('E', 'Assign each value an integer')\n",
        "dot.node('F', 'Replace string values with corresponding integers in data')\n",
        "dot.node('G', 'Normalize data between 0 and 1')\n",
        "dot.node('H', 'Convert selected columns to int64 type')\n",
        "dot.node('I', 'Split data into training and testing sets')\n",
        "dot.node('J', 'End')\n",
        "\n",
        "# Define edges\n",
        "dot.edges(['AB', 'BC', 'CD', 'DE', 'EF', 'FG', 'GH', 'HI', 'IJ'])\n",
        "\n",
        "# Render the flowchart\n",
        "display(Image(dot.render(format='png')))\n"
      ],
      "metadata": {
        "id": "bAxGCANlvu__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Create Digraph object\n",
        "dot = Digraph()\n",
        "\n",
        "# Define nodes with additional details\n",
        "nodes = {\n",
        "    'A': {'label': 'Start', 'shape': 'ellipse'},\n",
        "    'B': {'label': 'Define change_string_to_int\\nFunction to convert string values to integers', 'shape': 'box'},\n",
        "    'C': {'label': 'Extract unique values\\nfor the specified column', 'shape': 'parallelogram'},\n",
        "    'D': {'label': 'Iterate over unique values', 'shape': 'parallelogram'},\n",
        "    'E': {'label': 'Assign each value an integer', 'shape': 'parallelogram'},\n",
        "    'F': {'label': 'Replace string values with\\n corresponding integers in data', 'shape': 'parallelogram'},\n",
        "    'G': {'label': 'Normalize data between 0 and 1', 'shape': 'parallelogram'},\n",
        "    'H': {'label': 'Convert selected columns\\nto int64 type', 'shape': 'parallelogram'},\n",
        "    'I': {'label': 'Split data into\\ntraining and testing sets', 'shape': 'parallelogram'},\n",
        "    'J': {'label': 'End', 'shape': 'ellipse'}\n",
        "}\n",
        "\n",
        "# Add nodes to the graph\n",
        "for node, attrs in nodes.items():\n",
        "    dot.node(node, label=attrs['label'], shape=attrs['shape'])\n",
        "\n",
        "# Define edges\n",
        "edges = [\n",
        "    ('A', 'B'),\n",
        "    ('B', 'C'),\n",
        "    ('C', 'D'),\n",
        "    ('D', 'E'),\n",
        "    ('E', 'F'),\n",
        "    ('F', 'G'),\n",
        "    ('G', 'H'),\n",
        "    ('H', 'I'),\n",
        "    ('I', 'J')\n",
        "]\n",
        "\n",
        "# Add edges to the graph\n",
        "for edge in edges:\n",
        "    dot.edge(edge[0], edge[1])\n",
        "\n",
        "# Render the flowchart\n",
        "display(Image(dot.render(format='png')))\n"
      ],
      "metadata": {
        "id": "IOmgLhPHvxwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qD7YSNUAwZQV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}